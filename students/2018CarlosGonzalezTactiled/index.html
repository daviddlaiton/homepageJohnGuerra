<!DOCTYPE html>
<html lang="en">

</html>

<head>
    <meta charset="UTF-8" />
    <title>Tactile Graphics Finder</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css" integrity="sha384-9gVQ4dYFwwWSjIDZnLEWnxCjeSWFphJiwGPXr1jddIhOegiu1FwO5qRGvFXOdJZ4" crossorigin="anonymous" />
    <style>
    .thumb {
      margin: 10px;
    }
    .videoDemo {
      margin: 10px;
    }
    .white {
      color:white;
    }
    body {
      text-align:center;
    }    
    .justify {
      text-align:justify;
    }
    .footer {
      margin-bottom: 15px;
    }
  </style>
    </style>
</head>

<body>
    <div class="container">
        <div class="row">
            <div class="col-12">
                <h1>Machine Learning for the blind to "see"<br/><small>Evaluating images in order to see how good they can be as tactile graphics</small></h1>
                <p>Undergrad project by <a href="https://cegonzalv.github.io/">Carlos González</a> working under the supervision of <a href="http://johnguerra.co">John Alexis Guerra Gómez</a></p>
                <div class="row">
                  <div class="col-6">
                    <img width="500" src="https://f-martinez11.github.io/personalpage/img/thumbnail2.png" alt="TGF Project" class="thumb" />
                  </div>
                  <div class="col-6">
                    <img width="500" src="https://f-martinez11.github.io/personalpage/img/thumbnail2.png" alt="TGF Project" class="thumb" />
                  </div>
                </div>
                <br/>
                <br/>
                <a class="btn btn-primary" role="button" href="https://github.com/cegonzalv/tactileFinderNode/tree/d68b234f217f45a1c886866e0d1516aacf939d86">Github</a>
                <a class="btn btn-primary" role="button" href="https://tactiled.firebaseapp.com">Demo</a>
                <a class="btn btn-primary" role="button" href="https://infograph.venngage.com/ps/RTCkoiPL4Pc">Poster</a>
                <a class="btn btn-primary" role="button" href="https://www.overleaf.com/19124716tfrhzwykyjrd">Thesis</a>
                <br/>
                <br/>
                <span class="videoDemo"><iframe width="560" height="315" src="https://www.youtube.com/embed/tol7emv9KQE?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></span>
            </div>
        </div>
        <div class="row">
           <div class="col-2"></div>
            <div class="col-8">
                <h2>Objective</h2>
                <div class="justify">Tactiled is a tool prepared to test the quality of an image to be used as a tactile graphic.
                
                We want to develop and train a Machine Learning model that determines the quality of an image that will be transformed to a tactile graphic, by evaluating the facility for a blind person to understand its content</div></br>
                <div class="justify">
                All of this to accomplish our mission: "Making more images available to blind people"
                </div>
            </div>
             <div class="col-2"></div>
        </div>
        <br/>
        <div class="row">
           <div class="col-2"></div>
            <div class="col-8">
                <h2>Problem Statement</h2>
                <div class="justify">
                    According to the World Health Organization an estimated of 36 million people are blind 
                    and 217 million have some kind of visual impairment. For this population, access to digital 
                    images can be a challenge due to their disability. To overcome this problem, there are some 
                    techniques to represent a visual image on a tactile graphic that can be understood by blind people. 
                    However, the process of translating a visual image into a tactile graphic usually requires the 
                    intervention of a sighted person and the resulting image should be reviewed to determine its quality. 
                    Current technology could provide an automated way of finding and using tactile graphics without the need of 
                    a sighted person.
                </div>
            </div>
             <div class="col-2"></div>
        </div>
        <br/>
        <div class="row">
           <div class="col-2"></div>
            <div class="col-8 ">
                <h2>Deliverables</h2>
                <div class="justify footer">
                    1. A Machine Learning model capable of determining the quality of an image, quality understood as the facility for a blind person to understand its content, of a tactile graphic.
                    <br/> 2. A tool for users to test their own images.
                    <br/> 3. A small search engine that provides good images to transform to tactile graphics.
                </div>
                
            </div>
             <div class="col-2"></div>
        </div>
    </div>
</body>